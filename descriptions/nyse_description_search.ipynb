{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa912bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install packages in the notebook environment\n",
    "# Uncomment and run if you need to install dependencies:\n",
    "# !pip install pandas ipywidgets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99882dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn imports are optional (TF-IDF search). We'll try to import and fall back gracefully.\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import linear_kernel\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except Exception:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "# Repository-relative paths (adjust if your files live elsewhere)\n",
    "BASE = Path('.')\n",
    "TICKERS_PATH = BASE / 'FinancialWebScrapers' / 'tickers.json'\n",
    "DESCRIPTIONS_PATH = BASE / 'FinancialWebScrapers' / 'us-gaap-descriptions.json'\n",
    "KEYATTR_PATH = BASE / 'FinancialWebScrapers' / 'keyAttributes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7518f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_data():\n",
    "    # Load ticker/master list if available\n",
    "    tickers = []\n",
    "    if TICKERS_PATH.exists():\n",
    "        data = _load_json(TICKERS_PATH)\n",
    "        if isinstance(data, dict):\n",
    "            # dict-of-tickers or metadata; try to convert to list\n",
    "            try:\n",
    "                tickers = [v for v in data.values() if isinstance(v, dict)]\n",
    "            except Exception:\n",
    "                tickers = []\n",
    "        elif isinstance(data, list):\n",
    "            tickers = data\n",
    "\n",
    "    # Load descriptions into a mapping: ticker -> description\n",
    "    desc_map = {}\n",
    "    if DESCRIPTIONS_PATH.exists():\n",
    "        d = _load_json(DESCRIPTIONS_PATH)\n",
    "        if isinstance(d, dict):\n",
    "            # assume mapping ticker -> description OR name -> description\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, str):\n",
    "                    desc_map[k.upper()] = v\n",
    "        elif isinstance(d, list):\n",
    "            for item in d:\n",
    "                if isinstance(item, dict):\n",
    "                    # common keys: 'ticker', 'symbol', 'description', 'text'\n",
    "                    ticker = item.get('ticker') or item.get('symbol') or item.get('ciK') or item.get('cik')\n",
    "                    desc = item.get('description') or item.get('text') or item.get('value')\n",
    "                    if ticker and desc and isinstance(desc, str):\n",
    "                        desc_map[str(ticker).upper()] = desc\n",
    "\n",
    "    # Try keyAttributes.json as well for descriptions if present\n",
    "    if KEYATTR_PATH.exists():\n",
    "        k = _load_json(KEYATTR_PATH)\n",
    "        if isinstance(k, dict):\n",
    "            # some formats may contain entries with 'ticker' and 'description'\n",
    "            for entry in k.get('items', []) if 'items' in k else (k.get('companies', []) if 'companies' in k else []):\n",
    "                if isinstance(entry, dict):\n",
    "                    t = entry.get('ticker') or entry.get('symbol')\n",
    "                    desc = entry.get('description')\n",
    "                    if t and desc:\n",
    "                        desc_map[str(t).upper()] = desc\n",
    "\n",
    "    # Build DataFrame from tickers list if available, else try to build from desc_map\n",
    "    rows = []\n",
    "    if tickers:\n",
    "        for item in tickers:\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "            ticker = (item.get('ticker') or item.get('symbol') or item.get('Ticker') or item.get('symbol'))\n",
    "            if ticker is None:\n",
    "                # try keys that look like tickers\n",
    "                for k in item.keys():\n",
    "                    if isinstance(k, str) and len(k) <= 5 and k.isupper():\n",
    "                        ticker = k\n",
    "                        break\n",
    "            name = item.get('name') or item.get('company') or item.get('longName') or item.get('Company Name')\n",
    "            exchange = item.get('exchange') or item.get('Exchange') or item.get('market')\n",
    "            desc = None\n",
    "            if ticker:\n",
    "                desc = desc_map.get(str(ticker).upper())\n",
    "            # if item itself contains a description field, prefer it\n",
    "            if not desc:\n",
    "                desc = item.get('description') or item.get('text')\n",
    "            rows.append({'ticker': (str(ticker).upper() if ticker else None), 'name': name, 'exchange': exchange, 'description': desc})\n",
    "    else:\n",
    "        # Fall back: create rows from desc_map only\n",
    "        for t, desc in desc_map.items():\n",
    "            rows.append({'ticker': t, 'name': None, 'exchange': None, 'description': desc})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Normalize columns\n",
    "    if 'exchange' in df.columns:\n",
    "        df['exchange'] = df['exchange'].fillna('').astype(str)\n",
    "    else:\n",
    "        df['exchange'] = ''\n",
    "    df['ticker'] = df['ticker'].astype('string')\n",
    "    df['name'] = df['name'].astype('string')\n",
    "    df['description'] = df['description'].fillna('').astype('string')\n",
    "    # Filter to NYSE listings (case-insensitive substring match)\n",
    "    mask = df['exchange'].str.contains('NYSE', case=False, na=False)\n",
    "    df_nyse = df[mask].copy() if mask.any() else df.copy()\n",
    "    df_nyse.reset_index(drop=True, inplace=True)\n",
    "    return df_nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (this will try repo JSON files and build a table)\n",
    "df = load_data()\n",
    "print(f'Loaded {len(df)} companies (filtered to NYSE where available).')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee856e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_search(df, query, regex=False):\n",
    "    if not query:\n",
    "        return df.iloc[0:0]\n",
    "    q = str(query)\n",
    "    if regex:\n",
    "        mask = df['description'].str.contains(q, case=False, regex=True, na=False)\n",
    "        counts = df['description'].str.count(q, flags=re.IGNORECASE).fillna(0).astype(int)\n",
    "    else:\n",
    "        esc = re.escape(q)\n",
    "        mask = df['description'].str.contains(esc, case=False, regex=True, na=False)\n",
    "        counts = df['description'].str.count(esc, flags=re.IGNORECASE).fillna(0).astype(int)\n",
    "    res = df[mask].copy()\n",
    "    res['matches'] = counts[mask].values\n",
    "    res = res.sort_values('matches', ascending=False)\n",
    "    return res\n",
    "\n",
    "def tfidf_search(df, query, top_n=50):\n",
    "    if not SKLEARN_AVAILABLE:\n",
    "        raise RuntimeError('scikit-learn is required for TF-IDF search')\n",
    "    docs = df['description'].fillna('').astype(str).tolist()\n",
    "    vect = TfidfVectorizer(stop_words='english')\n",
    "    tfidf = vect.fit_transform(docs)\n",
    "    qv = vect.transform([query])\n",
    "    sim = linear_kernel(qv, tfidf).flatten()\n",
    "    idx = np.argsort(sim)[::-1][:top_n]\n",
    "    res = df.iloc[idx].copy()\n",
    "    res['score'] = sim[idx]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive widgets UI (ipywidgets)\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "query = widgets.Text(description='Query', placeholder='Enter keyword or phrase')\n",
    "method = widgets.Dropdown(options=['Simple', 'Regex', 'TF-IDF'], value='Simple', description='Method')\n",
    "top_n = widgets.IntSlider(value=20, min=1, max=200, description='Top')\n",
    "search_btn = widgets.Button(description='Search', button_style='primary')\n",
    "export_btn = widgets.Button(description='Export CSV')\n",
    "out = widgets.Output(layout={'max_height':'400px', 'overflow':'auto'})\n",
    "\n",
    "def _do_search(_):\n",
    "    out.clear_output()\n",
    "    q = query.value.strip()\n",
    "    if not q:\n",
    "        with out:\n",
    "            print('Please enter a query string')\n",
    "        return\n",
    "    try:\n",
    "        if method.value == 'Simple':\n",
    "            res = simple_search(df, q, regex=False)\n",
    "            display_cols = ['ticker', 'name', 'description', 'matches']\n",
    "        elif method.value == 'Regex':\n",
    "            res = simple_search(df, q, regex=True)\n",
    "            display_cols = ['ticker', 'name', 'description', 'matches']\n",
    "        else:\n",
    "            if not SKLEARN_AVAILABLE:\n",
    "                with out:\n",
    "                    print('scikit-learn not available; install it to use TF-IDF search')\n",
    "                return\n",
    "            res = tfidf_search(df, q, top_n=top_n.value)\n",
    "            display_cols = ['ticker', 'name', 'description', 'score']\n",
    "        with out:\n",
    "            if res.empty:\n",
    "                print('No matches found')\n",
    "            else:\n",
    "                display(res[display_cols].head(top_n.value))\n",
    "        # attach last results for export\n",
    "        out._last_results = res\n",
    "    except Exception as e:\n",
    "        with out:\n",
    "            print('Search error:', e)\n",
    "\n",
    "def _export(_):\n",
    "    last = getattr(out, '_last_results', None)\n",
    "    if last is None or last.empty:\n",
    "        with out:\n",
    "            print('No results to export')\n",
    "        return\n",
    "    fn = 'nyse_search_results.csv'\n",
    "    last.to_csv(fn, index=False)\n",
    "    with out:\n",
    "        print(f'Exported {len(last)} rows to {fn}')\n",
    "\n",
    "search_btn.on_click(_do_search)\n",
    "export_btn.on_click(_export)\n",
    "\n",
    "ui = widgets.HBox([query, method, top_n, search_btn, export_btn])\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed1b23",
   "metadata": {},
   "source": [
    "**Usage notes**:\n",
    "- Start by running the import/load cells (run the notebook top-to-bottom).\n",
    "- Use `Simple` for literal keyword matches, `Regex` for advanced patterns, and `TF-IDF` to find conceptually similar descriptions (requires `scikit-learn`).\n",
    "- After running a search, click `Export CSV` to save results to `nyse_search_results.csv`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
